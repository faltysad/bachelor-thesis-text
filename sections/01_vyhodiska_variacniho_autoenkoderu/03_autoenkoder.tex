\section{Autoenkodér}
Autoenkodér je typ umělé neuronové sítě schopný učit se efektivní reprezentace vstupních dat bez učitele. Umělá neuronová síť Autoenkodéru má symetrickou strukturu a skrytou vrstvu \emph{h}, která popisuje \emph{kód} použitý pro reprezentaci vstupu.
Architekturu sítě lze principiálně rozdělit na dvě části – kódovací funkci $h = f(x)$, resp. \textbf{enkodér}
a dekódovací funkci $r = g(h)$, resp \textbf{dekodér} (výstupem dekodéru je rekonstrukce vstupu \emph{r}).

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[round/.style={circle, draw, minimum size=10mm, node distance=25mm, on grid}]
        \node[round](h){h};
        \node[round](x)[below left of=h]{x};
        \node[round](r)[below right of=h]{r};
        
        \draw[-Triangle] (x) -- node [above] {f} (h);
        \draw[-Triangle] (h) -- node [above] {g} (r);
    \end{tikzpicture}
    \caption{Obecná struktura Autoenkodéru, mapující vstup $\mathbf{x}$ na rekonstrukci $\mathbf{r}$ skrze vnitřní reprezentaci (\emph{kód}) $\mathbf{h}$.}
\end{figure}


Autoenkodér má typicky totožnou architekturu jako Vícevrstvý Perceptron \autoref{sec:multilayer_perceptron}, s výjimkou rovnosti počtu neuronů ve výstupní vrstvě s počtem vstupů umělé neuronové sítě.
\subsection{Historický pohled}
Vícevrstvý Perceptron \autoref{sec:multilayer_perceptron} je univerzálním aproximátorem \autoref{sec:universal_approximation_theorem} – tedy historicky nalézá uplatnění zejména v klasifikačních úlohách učení s učitelem.
Sofistikovaný algoritmus se schopností trénování Vícevrstvého Perceptronu s větším počtem skrytých vrstev stále schází, a to zejména v důsledku problému mizejícího gradientu (\emph{vanishing gradient problem}).
Až příchod algoritmu gradientního sestupu \autoref{sec:gradient_descent}, který adresuje problém mizejícího gradientu v aplikacích s použitím konvolučních sítí \autoref{sec:cnn} a úloh učení se bez učitele, značí počátek moderních metod hlubokého učení.
V oblasti hlubokého učení \autoref{sec:deep_learning} dochází k emergenci a vývoji řady technik pro řešení úloh učení se bez učitele.
V této kapitole je popsána pouze jedna z nich – architektura umělé neuronové sítě založené na \emph{enkodér-dekodér} modulech: Autoenkodér. Autoenkodéry byly poprvé představeny jako způsob pro předtrénování umělých neuronových sítí (formou automatizované extrakce vlastností \emph{feature extraction}). 
Později Autoenkodéry nalézají uplatnění zejména v úloháh redukce dimenzionality \autoref{chap:dimensionality_reduction} či fůzi vlastností (\emph{feature fusion}).


Nedávné teoretické propojení Autoenkodéru a Modelů využívajících latentní proměnných \autoref{sec:latent_variable_models} však vedlo ke vzniku zcela nové architektury neuronové sítě kombinující charakter redukce dimenzionality Autoenkodéru se statistickými metodami odvozování.
To vyneslo Autoenkodéry na popředí v oblasti generativního modelování – této architektuře je věnována kapitola \autoref{chap:vae}.

Byť Autoenkodéry vznikly v kontextu hlubokého učení, není pravidlem že všechny modely Autoenkodéru obsahují vícero skrytých vrstev. Následuje rozdělení Autoenkodérů dle struktury umělé neuronové sítě.


\subsection{Neuplný autoenkodér // Undercomplete Autoencoder}

\subsection{Hlubuký autoenkodér}
Hluboký autoenkodér (\emph{stacked} autoenkodér)


\subsection{Řídký autoenkodér}

\subsection{Denoising autoenkodér}
\subsection{Contractive autoenkodér}

\subsection{Stochastický enkodér dekodér}


\subsection{Od Analýzy hlavních komponent po Autoenkodér}
% Autoenkodery already vykazuji lepsi vykonnost nez PCA (viz studie), narazi ale na jejich nespojitost, proto predsstavujeme VAE

\subsection{Taxonomie autoenkodérů}