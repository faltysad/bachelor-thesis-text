\section{Optimalizace pomocí stochastického gradientního sestupu}
\label{sec:vae_optimization}

Za účelem optimalizace pravé strany \autoref{eq:vae_elbo} je nutné specifikovat tvar, kterého bude $q_\phi(z\mid x)$ nabývat.

Bylo by možné pomocí vzorků odhadnout $\mathds{E}_{q_\phi(z\mid x^{(i)})} \left[ \log p_\theta(x^{(i)}\mid z) \right]$, ale pro získání \emph{věrohodného} odhadu je nutné skrze $z$ poslat velké množství vzorků, což je výpočetně náročné.
Tedy, jak je u stochastického gradientního sestupu běžné, využijeme pouze jeden vzorek $z$ a použijeme $P(X\mid z)$ pro toto $z$ jako aproximaci této střední hodnoty
\footnote{Zde je výhodou, že provést stochastický gradientní sestup skrze všechny různé hodnoty $X$ vzorkované z datové sady $D$ již stochastický gradientní sestup provádíme při trénování.}. \cite{Doersch2021}


Tedy \textbf{rovnice kterou chceme optimalizovat} má dle \textcite{Kingma2014} následující podobu:

\begin{align}
   \nabla_\phi \mathcal{L}_{\theta,\phi}(x) &= \nabla_\phi \mathds{E}_{q_\phi(z\mid x)} \left[ \log p_\theta (x, z) - \log q_\phi (z\mid x) \right] \label{eq:vae_final_objective} \\
                                            &\neq \mathds{E}_{q_\phi(z\mid x)} \left[ \nabla_\phi (\log p_\theta (x, z) - \log q_\phi (z\mid x) ) \right] \label{eq:vae_final_objective_dependent_gradient}
\end{align}

Symbol gradientu této může být bezpečně přesunut do střední hodnoty.
Tedy, můžeme vzorkovat jednu hodnotu z $X$ a jednu hodnotu ze $z$ z a následně vypočítat gradient \cite{Doersch2021}:

\begin{equation} \label{eq:sample_gradient}
    \log p_\theta(x \mid z) - D_{KL}(q_\phi(\textbf{z}\mid\textbf{x})\parallel p_\theta(\textbf{z})). 
\end{equation}

Průměr gradientu této funkce skrze \emph{libovolně velké} množství vzorků z $x$ a $z$. Výsledná hodnota tohoto gradientu konverguje ke gradientu \autoref{eq:vae_final_objective}. \cite{Doersch2021}

\subsection{Metoda stochastická gradientní optimalizace ELBO}
\label{sec:stochastic_gradient_optimization_method}
Důležitou vlastností ELBO (viz \autoref{eq:vae_elbo}) je možnost společné optimalizace s ohledem na veškeré její parametry – $\boldsymbol{\phi}$ a $\boldsymbol{\theta}$ – za použití stochastického gradientního sestupu (\emph{stochastic gradient descent, SGD}).
Proces lze zahájit náhodnými počátečními hodnotami $\boldsymbol{\phi}$ a $\boldsymbol{\theta}$ a stochasticky optimalizovat jejich hodnoty než dojde ke konvergenci. \cite{Kingma2019}

Mějme nezávisle a rovnoměrně rozdělená vstupní data, účelovou funkcí ELBO je součet ELBO jednotlivých datových bodů \cite{Kingma2019}:
\begin{equation}
    \mathcal{L}_{\theta,\phi}(\mathcal{D}) = \sum_{x\in\mathcal{D}}^{} \mathcal{L}_{\theta,\phi}(\textbf{x})
\end{equation}

ELBO jednotlivých datových bodů a jejich gradienty jsou \emph{obecně} efektivně řešitelné.
Dokonce existují estimátory bez biasu, za pomocí kterých lze provést minibatch SGD.

Gradienty ELBO bez biasu s ohledem na parametry generativního modelu $\boldsymbol{\theta}$ lze jednoduše získat (viz rovnice 2.14 - 2.17 z \cite{Kingma2019}).

Spočítat gradienty ELBO bez biasu s ohledem na variační parametry $\boldsymbol{\phi}$ je již složitější, jelikož tato ELBO je uvažována s ohledem na rozdělení pravděpodobnosti $q_\phi(\textbf{z}\mid\textbf{x})$, tedy je funkcí $\phi$. Nerovnost gradientů ELBO viz rovnice 2.18 - 2.19 z \cite{Kingma2019}.

V případě \textbf{spojitých} latentních proměnných lze využít tzv. \textbf{reparametrizačního triku} pro výpočet odhadů bez biasu $\nabla_{\theta,\phi}\mathcal{L}_{\theta,\phi}(\textbf{x})$.
Tento stochastický odhad umožňuje optimalizovat ELBO za SGD (viz \autoref{alg:reparam_trick})
\footnote{Existují i metody pro případ \textbf{diskrétních} latentních proměnných, které však pro předmět práce nejsou stěžejní. Pro jejich představení odkazuji na \cite[Sekce 2.9.1.]{Kingma2019}.}. Pseudokód algoritmu převzat z \cite{Kingma2019}.

Interpretaci pseudokódu, který zachycuje \autoref{alg:reparam_trick}, nabízí trénovací krok ztrátové funkce implementovaného modelu dle \autoref{sec:vae_model_reparametrization_layer}.

\begin{algorithm}[H]
    \caption{Metoda stochastická gradientní optimalizace ELBO}\label{alg:reparam_trick}
        \KwData{}
                \hspace{6mm}$\mathcal{D}$: Dataset (i. i. d.)\\
                \hspace{6mm}$q_\phi(\textbf{z}\mid\textbf{x})$: Inferenční model (enkodér)\\
                \hspace{6mm}$p_\theta(\textbf{x}, \textbf{z})$: Generativní model (dekodér)\\
        \KwResult{}
        \hspace{6mm}$\boldsymbol{\theta}, \boldsymbol{\phi}$: Naučené parametry\\

        $\boldsymbol{\theta}, \boldsymbol{\phi} \gets \text{Náhodná inicializace parametrů}$

        \While{SGD nezkonvergoval}{
            $\mathcal{M} \sim \mathcal{D}$ (Náhodný \emph{minibatch} vstupních dat)\\
            $\boldsymbol{\epsilon} \sim p(\boldsymbol{\epsilon})$ (Náhodný šum pro každý datový bod v $\mathcal{M}$)\\
            Vypočíst $\tilde{\mathcal{L}}$ and její gradienty $\nabla_{\theta,\phi}(\mathcal{M}, \boldsymbol{\epsilon})$\\
            Upravit $\boldsymbol{\theta}$ a $\boldsymbol{\phi}$ za použití SGD optimizéru
            }
\end{algorithm}

Aby VAE fungovaly dle očekávání, $q_\phi(z\mid x)$ musí být nuceno produkovat takové kódy pro $x$, které bude $p_\theta(x, z)$ schopno \textbf{spolehlivě} dekódovat.
Na tento problém lze alternativně pohlížet interpretací \autoref{eq:vae_final_objective} jakožto sítě, kterou zobrazuje \autoref{fig:vae_backpropagation}(a).
Dopředný průchod této sítě funguje bez problémů – a je-li její výstup zprůměrován skrze mnoho vzorků $x$ a $z$, produkuje správnou střední hodnotu.
Nicméně, je nutné mít schopnost zpětně propagovat chybu skrze vrstvu, která vzorkuje $z$ z $q_\phi(z \mid x)$, což je \textbf{nespojitá operace} a tedy nemá žádný gradient.
Stochastický gradientní sestup se zpětnou propagací zvládne stochastické vstupy, ale \textbf{neumí pracovat se stochastickými jednotkami (neurony) sítě}.

Řešení tohoto problému nazýváme \textbf{reparametrizační trik}.